# HotSpot的算法细节实现

## 根节点枚举

我们以可达性分析算法中从GC Roots集合找引用链这个操作作为介绍虚拟机高效实现的第一个例子。固定可作为GC Roots的节点主要在`全局性的引用(例如常量或类静态属性)与执行上下文(例如栈帧中的本地变量表)中`，尽管目标明确，但查找过程要做到高效并非一件容易的事情，现在Java应用越做越庞大，光是方法区的大小就常有数百上千兆，里面的类、常量等更是恒河沙数，若要逐个检 查以这里为起源的引用肯定得消耗不少时间。

迄今为止，`所有收集器在根节点枚举这一步骤时都是必须暂停用户线程的`，因此毫无疑问根节点枚举与之前提及的整理内存碎片一样会面临相似的“Stop The World”的困扰。现在可达性分析算法耗时最长的查找引用链的过程已经可以做到与用户线程一起并发，但根节点枚举始终还是必须在一个能保障一致性的快照中才得以进行——这里“一致性”的意思是整个枚举期间执行子系统看起来就像被冻结在某个时间点上，不会出现分析过程中，根节点集合的对象引用关系还在不断变化的情况，若这点不能满足的话，分析结果准确性也就无法保证。`这是导致垃圾收集过程必须停顿所有用户线程的其中一个重要原因`，即使是号称停顿时间可控，或者(几乎)不会发生停顿的CMS、G1、 ZGC等收集器，枚举根节点时也是必须要停顿的。

由于目前主流Java虚拟机使用的都是准确式垃圾收集，所以当用户线程停顿下来之后，其实并不需要一个不漏地检查完所有执行上下文和全局的引用位置，虚拟机应当是有办法直接得到哪些地方存放着对象引用的。

在HotSpot的解决方案里，是`使用一组称为OopMap的数据结构来达到这个目的`。`一旦类加载动作完成的时候， HotSpot就会把对象内什么偏移量上是什么类型的数据计算出来，在即时编译过程中，也会在特定的位置记录下栈里和寄存器里哪些位置是引用`。这样收集器在扫描时就可以直接得知这些信息了，并不需要真正一个不漏地从方法区等GC Roots开始查找。

下面代码清单3-3是HotSpot虚拟机客户端模式下生成的一段String::hashCode()方法的本地代码，可 以看到在0x026eb7a9处的call指令有OopMap记录，它指明了EBX寄存器和栈中偏移量为16的内存区域 中各有一个普通对象指针(Ordinary Object Pointer，OOP)的引用，有效范围为从call指令开始直到0x026eb730(指令流的起始位置)+142(OopMap记录的偏移量)=0x026eb7be，即hlt指令为止。

![image-20201205164145154](https://gitee.com/zisuu/picture/raw/master/img/20201205164145.png)

## 安全点

在OopMap的协助下，HotSpot可以快速准确地完成GC Roots枚举，但一个很现实的问题随之而 来:可能导致引用关系变化，或者说导致OopMap内容变化的指令非常多，如果为每一条指令都生成对应的OopMap，那将会需要大量的额外存储空间，这样垃圾收集伴随而来的空间成本就会变得无法忍受的高昂。

`实际上HotSpot也的确没有为每条指令都生成OopMap`，前面已经提到，只是在“特定的位置”记录 了这些信息，这些位置被称为`安全点(Safepoint)`。有了安全点的设定，也就决定了用户程序执行时并非在代码指令流的任意位置都能够停顿下来开始垃圾收集，而是`强制要求必须执行到达安全点后才能够暂停`。因此，安全点的选定既不能太少以至于让收集器等待时间过长，也不能太过频繁以至于过 分增大运行时的内存负荷。

安全点位置的选取基本上是以`“是否具有让程序长时间执行的特征”为标准进行选定的`，因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这样的原因而长时间执行，“长时间执行”的最明显特征就是`指令序列的复用`，例如`方法调用、循环跳转、异常跳转`等都属于指令序列复用，所以只有具有这些功能的指令才会产生安全点。

对于安全点，另外一个需要考虑的问题是，如何在垃圾收集发生时让所有线程(这里其实`不包括执行JNI调用的线程`)都跑到最近的安全点，然后停顿下来。

这里有两种方案可供选择:`抢先式中断 (Preemptive Suspension)`和`主动式中断(Voluntary Suspension)`

- 抢先式中断不需要线程的执行代码主动去配合，在垃圾收集发生时，系统首先把所有用户线程全部中断，如果发现有用户线程中断的地方不在安全点上，就恢复这条线程执行，让它一会再重新中断，直到跑到安全点上。`现在几乎没有虚 拟机实现采用抢先式中断来暂停线程响应GC事件`。
- 而主动式中断的思想是当垃圾收集需要中断线程的时候，不直接对线程操作，仅仅简单地设置一个标志位，`各个线程执行过程时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起`。轮询标志的地方和安全点是重合的，另外还要`加上所有创建对象和其他需要在Java堆上分配内存的地方`，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象。

由于轮询操作在代码中会频繁出现，这要求它必须足够高效。HotSpot使用`内存保护陷阱的方式`， 把轮询操作精简至只有一条汇编指令的程度。下面代码清单3-4中的test指令就是HotSpot生成的轮询指令，当需要暂停用户线程时，虚拟机把0x160100的内存页设置为不可读，那线程执行到test指令时就会产生一个自陷异常信号，然后在预先注册的异常处理器中挂起线程实现等待，这样仅通过一条汇编指令便完成安全点轮询和触发线程中断了。

![image-20201205164708167](https://gitee.com/zisuu/picture/raw/master/img/20201205164708.png)

## 安全区域

使用安全点的设计似乎已经完美解决如何停顿用户线程，让虚拟机进入垃圾回收状态的问题了， 但实际情况却并不一定。安全点机制保证了程序执行时，在不太长的时间内就会遇到可进入垃圾收集过程的安全点。但是，程序“不执行”的时候呢?所谓的程序不执行就是没有分配处理器时间，典型的场景便是`用户线程处于Sleep 状态或者Blocked状态`，这时候线程无法响应虚拟机的中断请求，不能再走到安全的地方去中断挂起自己，虚拟机也显然不可能持续等待线程重新被激活分配处理器时间。对于这种情况，就必须引入安全区域(Safe Region)来解决。

`安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化`，因此，在这个区域中任意地方开始垃圾收集都是安全的。我们也可以把安全区域看作被扩展拉伸了的安全点。

当用户线程执行到安全区域里面的代码时，首先`会标识自己已经进入了安全区域`，那样当这段时间里虚拟机要发起垃圾收集时就不必去管这些已声明自己在安全区域内的线程了。`当线程要离开安全区域时，它要检查虚拟机是否已经完成了根节点枚举(或者垃圾收集过程中其他需要暂停用户线程的阶段)`，如果完成了，那线程就当作没事发生过，继续执行;否则它就必须一直等待，直到收到可以离开安全区域的信号为止。

## 记忆集与卡表

在垃圾收集,扫描时,有可能会发生老生代引用新生代对象的跨代问题,为此,垃圾收集器在新生代中建立了名为记忆集(Remembered Set)的数据结构,标记了老生代中哪些区域可能会引用新生代,从而避免把整个老年代加进GC Roots扫描范围`。

事实上并不只是新生代、老年代之间才有跨代引用的问题，所有涉及部分区域收集(Partial GC)行为的垃圾 收 集 器 ， 典 型 的 如 G 1 、 Z G C 和 Sh e n a n d o a h 收 集 器 ， 都 会 面 临 相 同 的 问 题 ， 因 此 我 们 有 必 要 进 一 步 理清记忆集的原理和实现方式，以便在后续章节里介绍几款最新的收集器相关知识时能更好地理解。

`记忆集是一种用于记录从非收集区域指向收集区域的指针集合的抽象数据结构`。如果我们不考虑效率和成本的话，最简单的实现可以用非收集区域中所有含跨代引用的对象数组来实现这个数据结构，如代码清单3-5所示:

![image-20201206180043113](https://gitee.com/zisuu/picture/raw/master/img/20201206180043.png)

这种记录全部含跨代引用对象的实现方案，无论是空间占用还是维护成本都相当高昂。而在垃圾收集的场景中，收集器只需要通过记忆集判断出某一块非收集区域是否存在有指向了收集区域的指针就可以了，并不需要了解这些跨代指针的全部细节。那设计者在实现记忆集的时候，便可以选择更为 粗犷的记录粒度来节省记忆集的存储和维护成本，下面列举了一些可供选择(当然也可以选择这个范 围以外的)的记录精度:

- `字长精度:`每个记录精确到一个机器字长(就是处理器的寻址位数，如常见的32位或64位，这个 精度决定了机器访问物理内存地址的指针长度)，该字包含跨代指针。
- `对象精度:`每个记录精确到一个对象，该对象里有字段含有跨代指针。
- `卡精度:`每个记录精确到一块内存区域，该区域内有对象含有跨代指针。

其中，第三种`“卡精度”所指的是用一种称为“卡表”(Card Table)的方式去实现记忆集`，这也是目前最常用的一种记忆集实现形式，一些资料中甚至直接把它和记忆集混为一谈。前面定义中提到记忆集其实是一种“抽象”的数据结构，抽象的意思是只定义了记忆集的行为意图，并没有定义其行为的具体实现。`卡表就是记忆集的一种具体实现，它定义了记忆集的记录精度、与堆内存的映射关系等`。 关于卡表与记忆集的关系，读者不妨按照Java语言中HashMap与Map的关系来类比理解。

卡表最简单的形式可以只是一个字节数组，而HotSpot虚拟机确实也是这样做的。以下这行代码是HotSpot默认的卡表标记逻辑:
![image-20201205170343241](https://gitee.com/zisuu/picture/raw/master/img/20201205170343.png)

`字节数组CARD_TABLE的每一个元素都对应着其标识的内存区域中一块特定大小的内存块，这个内存块被称作“卡页”(Card Page)`。一般来说，`卡页大小都是以2的N次幂的字节数`，通过上面代码可以看出HotSpot中使用的卡页是2的9次幂，即`512字节(地址右移9位，相当于用地址除以512)`。那如果卡表标识内存区域的起始地址是0x0000的话，数组CARD_TABLE的第0、1、2号元素，分别对应了
`地址范围为0x0000~0x01FF、0x0200~0x03FF、0x0400~0x05FF的卡页内存块`，如图3-5所示。

![image-20201205170747508](https://gitee.com/zisuu/picture/raw/master/img/20201205170747.png)

一个卡页的内存中通常包含不止一个对象，`只要卡页内有一个(或更多)对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，称为这个元素变脏(Dirty)，没有则标识为0`。在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把它们加入GC Roots中一并扫描。

## 写屏障

我们已经解决了如何使用记忆集来缩减GC Roots扫描范围的问题，但还没有解决卡表元素如何维护的问题，例如它们何时变脏、谁来把它们变脏等。

卡表元素何时变脏的答案是很明确的——`有其他分代区域中对象引用了本区域对象时，其对应的卡表元素就应该变脏，变脏时间点原则上应该发生在引用类型字段赋值的那一刻`。

但问题是如何变脏，即如何在对象赋值的那一刻去更新维护卡表呢?假如是解释执行的字节码，那相对好处理，虚拟机负责每条字节码指令的执行，有充分的介入空间;但在编译执行的场景中呢?经过即时编译后的代 码已经是纯粹的机器指令流了，这就必须找到一个在机器码层面的手段，把维护卡表的动作放到每一 个赋值操作之中。

`在HotSpot虚拟机里是通过写屏障(Write Barrier)技术维护卡表状态的`。先请读者注意将这里提到的“写屏障”，以及后面在低延迟收集器中会提到的“读屏障”与解决并发乱序执行问题中的“内存屏障”区分开来，避免混淆。

`写屏障可以看作在虚拟机层面对“引用类型字段赋值”这个动作的AOP切面，在引用对象赋值时会产生一个环形(Around)通知，供程序执行额外的动作，也就是说赋值的前后都在写屏障的覆盖范畴内`。在赋值前的部分的写屏障叫作写前屏障(Pre-Write Barrier)，在赋值后的则叫作写后屏障(Post-Write Barrier)。HotSpot虚拟机的许多收集器中都有使用到写屏障，但直至G1收集器出现之前，其他收集器都只用到了写后屏障。下面这段代码清单3-6是一段更新卡表状态的简化逻辑:

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200404192711238.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2NvbGRfX19wbGF5,size_16,color_FFFFFF,t_70)

应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令，一旦收集器在写屏障中增加了更新卡表操作，无论更新的是不是老年代对新生代对象的引用，每次只要对引用进行更新，就会产生额外的开销，不过这个开销与Minor GC时扫描整个老年代的代价相比还是低得多的。

除了写屏障的开销外，卡表在高并发场景下还面临着“伪共享”(False Sharing)问题。`伪共享是处理并发底层细节时一种经常需要考虑的问题，现代中央处理器的缓存系统中是以缓存行(Cache Line) 为单位存储的，当多线程修改互相独立的变量时，如果这些变量恰好共享同一个缓存行，就会彼此影响(写回、无效化或者同步)而导致性能降低`，这就是伪共享问题。

假设处理器的缓存行大小为64字节，由于一个卡表元素占1个字节，64个卡表元素将共享同一个缓存行。这64个卡表元素对应的卡页总的内存为32KB(64×512字节)，也就是说如果不同线程更新的对象正好处于这32KB的内存区域内，就会导致更新卡表时正好写入同一个缓存行而影响性能。为了避免伪共享问题，一种简单的解决方案是`不采用无条件的写屏障，而是先检查卡表标记，只有当该卡表元素未被标记过时才将其标记为变脏`

在JDK 7之后，HotSpot虚拟机增加了一个新的参数`-XX:+UseCondCardMark`，用来决定是否开启 卡表更新的条件判断。开启会增加一次额外判断的开销，但能够避免伪共享问题，两者各有性能损耗，是否打开要根据应用实际运行情况来进行测试权衡。

## 并发的可达性分析

当前主流编程语言的垃圾收集器基本上都是依靠可达性分析算法来判定对象是否存活的，可达性分析算法理论上要求全过程都基于一个能保障一致性的快照中才能够进行分析， 这意味着必须全程冻结用户线程的运行。

在根节点枚举这个步骤中，由于GC Roots相比起整个Java堆中全部的对象毕竟还算是极少数，且在各种优化技巧(如OopMap)的加持下，它带来的停顿已经是非常短暂且相对固定(不随堆容量而增长)的了。

可从GC Roots再继续往下遍历对象图，这一步骤的停顿时间就必定会与Java堆容量直接成正比例关系了:堆越大，存储的对象越多，对象图结构越复杂，要标记更多对象而产生的停顿时间自然就更长，这听起来是理所当然的事情。

要知道包含“标记”阶段是所有追踪式垃圾收集算法的共同特征，如果这个阶段会随着堆变大而等比例增加停顿时间，其影响就会波及几乎所有的垃圾收集器，同理可知，如果能够削减这部分停顿时间的话，那收益也将会是系统性的。

想解决或者降低用户线程的停顿，就要先搞清楚为什么必须在一个能保障一致性的快照上才能进行对象图的遍历?为了能解释清楚这个问题，我们引入三色标记(Tri-color Marking)作为工具来辅助推导，把遍历对象图过程中遇到的对象，按照“是否访问过”这个条件标记成以下三种颜色:

- 白色:表示对象尚未被垃圾收集器访问过。显然在可达性分析刚刚开始的阶段，所有的对象都是白色的，若在分析结束的阶段，仍然是白色的对象，即代表不可达。
- 黑色:表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经扫描过。黑色的对象代表已经扫描过，它是安全存活的，如果有其他对象引用指向了黑色对象，无须重新扫描一遍。黑色对象不可能直接(不经过灰色对象)指向某个白色对象。
- 灰色:表示对象已经被垃圾收集器访问过，但这个对象上至少存在一个引用还没有被扫描过。

关于可达性分析的扫描过程，读者不妨发挥一下想象力，把它看作对象图上一股以灰色为波峰的 波纹从黑向白推进的过程，如果用户线程此时是冻结的，只有收集器线程在工作，那不会有任何问 题。但如果用户线程与收集器是并发工作呢?收集器在对象图上标记颜色，同时用户线程在修改引用 关系——即修改对象图的结构，这样可能出现两种后果。

- 一种是把原本消亡的对象错误标记为存活， 这不是好事，但其实是可以容忍的，只不过产生了一点逃过本次收集的浮动垃圾而已，下次收集清理 掉就好。

- 另一种是把原本存活的对象错误标记为已消亡，这就是非常致命的后果了，程序肯定会因此 发生错误，下面表3-1演示了这样的致命错误具体是如何产生的。

  ![image-20201205221945231](https://gitee.com/zisuu/picture/raw/master/img/20201205221945.png)

![image-20201205222045510](https://gitee.com/zisuu/picture/raw/master/img/20201205222045.png)size_16,color_FFFFFF,t_70)

Wilson于1994年在理论上证明了，当且仅当以下两个条件同时满足时，会产生“对象消失”的问 题，即原本应该是黑色的对象被误标为白色:

- 赋值器插入了一条或多条从黑色对象到白色对象的新引用;
- 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。

因此，我们要解决并发扫描时的对象消失问题，只需破坏这两个条件的任意一个即可。由此分别产生了两种解决方案:`增量更新(Incremental Update)`和`原始快照(Snapshot At The Beginning， SATB )`。

- 增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。这可以简化理解为，`黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了`。
- 原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次。这也可以简化理解为，`无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照来进行搜索`。

以上无论是对引用关系记录的插入还是删除，虚拟机的记录操作都是通过写屏障实现的。在 HotSpot虚拟机中，增量更新和原始快照这两种解决方案都有实际应用，譬如，`CMS是基于增量更新来做并发标记的`，`G1、Shenandoah则是用原始快照来实现。`

到这里，笔者简要介绍了HotSpot虚拟机如何发起内存回收、如何加速内存回收，以及如何保证回 收正确性等问题，但是虚拟机如何具体地进行内存回收动作仍然未涉及。因为内存回收如何进行是由 虚拟机所采用哪一款垃圾收集器所决定的，而通常虚拟机中往往有多种垃圾收集器，下面笔者将逐一 介绍HotSpot虚拟机中出现过的垃圾收集器。



# HotSpot 垃圾收集器

## Serial收集器

`Serial收集器是最基础、历史最悠久的收集器，曾经(在JDK 1.3.1之前)是HotSpot虚拟机新生代收集器的唯一选择`。大家只看名字就能够猜到，这个收集器`是一个单线程工作的收集器`，但它的“单线 程”的意义并不仅仅是说明它只会使用一个处理器或一条收集线程去完成垃圾收集工作，更重要的是强调在`它进行垃圾收集时，必须暂停其他所有工作线程，直到它收集结束`。“Stop The World”这个词语也 许听起来很酷，但这项工作是由虚拟机在后台自动发起和自动完成的，在用户不可知、不可控的情况下把用户的正常工作的线程全部停掉，这对很多应用来说都是不能接受的。读者不妨试想一下，要是 你的电脑每运行一个小时就会暂停响应五分钟，你会有什么样的心情?图3-7示意了Serial/Serial Old收 集器的运行过程。

![image-20201205222605950](https://gitee.com/zisuu/picture/raw/master/img/20201205222606.png)

写到这里，笔者似乎已经把Serial收集器描述成一个最早出现，但目前已经老而无用，食之无味， 弃之可惜的“鸡肋”了，但事实上，迄今为止，`它依然是HotSpot虚拟机运行在客户端模式下的默认新生代收集器`，有着优于其他收集器的地方，那就是`简单而高效(与其他收集器的单线程相比)，对于内存资源受限的环境，它是所有收集器里额外内存消耗(Memory Footprint)[1]最小的`;对于单核处理 器或处理器核心数较少的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以 获得最高的单线程收集效率。**在用户桌面的应用场景以及近年来流行的部分微服务应用中，分配给虚拟机管理的内存一般来说并不会特别大**，收集几十兆甚至一两百兆的新生代(仅仅是指新生代使用的 内存，桌面应用甚少超过这个容量)，垃圾收集的停顿时间完全可以控制在十几、几十毫秒，最多一 百多毫秒以内，只要不是频繁发生收集，这点停顿时间对许多用户来说是完全可以接受的。所以，`Serial收集器对于运行在客户端模式下的虚拟机来说是一个很好的选择。`

## ParNew收集器

`ParNew收集器实质上是Serial收集器的多线程并行版本`，除了同时使用多条线程进行垃圾收集之外 ， 其 余 的 行 为 包 括 Se r i a l 收 集 器 可 用 的 所 有 控 制 参 数 ( 例 如 : `- X X : Su r v i v o r R a t i o 、 - X X : PretenureSizeThreshold、-XX:HandlePromotionFailure等`)、收集算法、Stop The World、对象分配规 则、回收策略等都与Serial收集器完全一致，在实现上这两种收集器也共用了相当多的代码。ParNew收 集器的工作过程如图3-8所示。

![image-20201205222843047](https://gitee.com/zisuu/picture/raw/master/img/20201205222843.png)

ParNew收集器除了支持多线程并行收集之外，其他与Serial收集器相比并没有太多创新之处，但它却是不少运行在服务端模式下的HotSpot虚拟机，尤其是JDK 7之前的遗留系统中首选的新生代收集器，其中有一个与功能、性能无关但其实很重要的原因是:`除了Serial收集器外，目前只有它能与CMS 收集器配合工作。`

在JDK 5发布时，HotSpot推出了一款在强交互应用中几乎可称为具有划时代意义的垃圾收集器 ——CMS收集器。这款收集器是HotSpot虚拟机中`第一款真正意义上支持并发的垃圾收集器`，它首次实现了让垃圾收集线程与用户线程(基本上)同时工作。

遗憾的是，CMS作为老年代的收集器，却`无法与JDK 1.4.0中已经存在的新生代收集器Parallel Scavenge配合工作`，所以在JDK 5中使用CMS来收集老年代的时候，新生代只能选择ParNew或者 Serial收集器中的一个。

ParNew收集器是激活CMS后(使用`-XX:+UseConcMarkSweep GC`选项)的默认新生代收集器，也可以使用`-XX:+/-UseParNewGC`选项来强制指定或者禁用它。

可以说直到CMS的出现才巩固了ParNew的地位，但成也萧何败也萧何，随着垃圾收集器技术的不断改进，更先进的G1收集器带着CMS继承者和替代者的光环登场。`G1是一个面向全堆的收集器，不再需要其他新生代收集器的配合工作`。

所以自JDK 9开始，ParNew加CMS收集器的组合就不再是官方推荐的服务端模式下的收集器解决方案了。官方希望它能完全被G1所取代，甚至还取消了ParNew加 Serial Old以及Serial加CMS这两组收集器组合的支持(其实原本也很少人这样使用)，并直接`取消了- XX:+UseParNewGC`参数，这意味着ParNew和CMS从此只能互相搭配使用，再也没有其他收集器能够和它们配合了。读者也可以理解为从此以后，ParNew合并入CM S，成为它专门处理新生代的组成部分。ParNew可以说是HotSpot虚拟机中第一款退出历史舞台的垃圾收集器。

`ParNew收集器在单核心处理器的环境中绝对不会有比Serial收集器更好的效果`，甚至由于存在线程交互的开销，该收集器在通过超线程(Hyper-Threading)技术实现的伪双核处理器环境中都不能百分之百保证超越Serial收集器。当然，随着可以被使用的处理器核心数量的增加，ParNew对于垃圾收集时 系统资源的高效利用还是很有好处的。它`默认开启的收集线程数与处理器核心数量相同`，在处理器核 心非常多(譬如32个，现在CPU都是多核加超线程设计，服务器达到或超过32个逻辑核心的情况非常普遍)的环境中，`可以使用-XX:ParallelGCT hreads参数来限制垃圾收集的线程数`。

## Parallel Scavenge收集器

`Parallel Scavenge收集器也是一款新生代收集器，它同样是基于标记-复制算法实现的收集器`，也是 能够并行收集的多线程收集器…Parallel Scavenge的诸多特性从表面上看和ParNew非常相似，那它有 什么特别之处呢?

Parallel Scavenge收集器的特点是它的关注点与其他收集器不同，CMS等收集器的关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而`Parallel Scavenge收集器的目标则是达到一个可控制的吞吐 量(Throughput)`。所谓吞吐量就是处理器用于运行用户代码的时间与处理器总消耗时间的比值， 即:
![image-20201206211531559](https://gitee.com/zisuu/picture/raw/master/img/20201206211531.png)
如果虚拟机完成某个任务，用户代码加上垃圾收集总共耗费了100分钟，其中垃圾收集花掉1分 钟，那吞吐量就是99%。

- 停顿时间越短就越适合需要与用户交互或需要保证服务响应质量的程序，良好的响应速度能提升用户体验;
- **而高吞吐量则可以最高效率地利用处理器资源，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的分析任务。**

Parallel Scavenge收集器提供了两个参数用于精确控制吞吐量，分别是`控制最大垃圾收集停顿时间的-XX:MaxGCPauseMillis`参数以及`直接设置吞吐量大小的-XX:GCTimeRatio参数`。

- -XX:MaxGCPauseMillis参数允许的值是一个大于0的毫秒数，收集器将尽力保证内存回收花费的 时间不超过用户设定值。不过大家不要异想天开地认为如果把这个参数的值设置得更小一点就能使得 系统的垃圾收集速度变得更快，垃圾收集停顿时间缩短是以牺牲吞吐量和新生代空间为代价换取的: 系统把新生代调得小一些，收集300M B新生代肯定比收集500M B快，但这也直接导致垃圾收集发生得 更频繁，原来10秒收集一次、每次停顿100毫秒，现在变成5秒收集一次、每次停顿70毫秒。停顿时间的确在下降，但吞吐量也降下来了。
- -XX:GCTimeRatio参数的值则应当是一个大于0小于100的整数，也就是垃圾收集时间占总时间的 比率，相当于吞吐量的倒数。譬如把此参数设置为19，那允许的最大垃圾收集时间就占总时间的5% (即1/(1+19))，默认值为99，即允许最大1%(即1/(1+99))的垃圾收集时间。

由于与吞吐量关系密切，`Parallel Scavenge收集器也经常被称作“吞吐量优先收集器”`。除上述两个 参数之外，Parallel Scavenge收集器还有一个参数`-XX:+UseAdaptiveSizePolicy`值得我们关注。

这是一 个开关参数，`当这个参数被激活之后，就不需要人工指定新生代的大小(-Xmn)、Eden与Survivor区 的 比 例 ( - X X : Su r v i v o r R a t i o ) 、 晋 升 老 年 代 对 象 大 小 ( - X X : P r e t e n u r e Si z e T h r e s h o l d ) 等 细 节 参 数 了`，虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。这种调节方式称为垃圾收集的自适应的调节策略(GC Ergonomics)。

## Serial Old收集器

`Serial Old是Serial收集器的老年代版本，它同样是一个单线程收集器，使用标记-整理算法`。这个收集器的主要意义也是`供客户端模式下的HotSpot虚拟机使用`。
如果在服务端模式下，它也可能有两种用途:

- 一种是在JDK 5以及之前的版本中与Parallel Scavenge收集器搭配使用
- 另外一种就是作为CMS 收集器发生失败时的后备预案，在并发收集发生Concurrent Mode Failure时使用。这两点都将在后面的内容中继续讲解。Serial Old收集器的工作过程如图3-9所示。

![image-20201205223735313](https://gitee.com/zisuu/picture/raw/master/img/20201205223735.png)

注意：需要说明一下，`Parallel Scavenge收集器架构中本身有PS MarkSweep收集器来进行老年代收集`，并非直接调用Serial Old收集器，但是这个`PS MarkSweep收集器与Serial Old的实现几乎是一样的`，所以在官方的许多资料中都是直接以Serial Old代替PS MarkSweep进行讲解，这里笔者也采用这种方式。

## Parallel Old收集器

`Parallel Old是Parallel Scavenge收集器的老年代版本，支持多线程并发收集，基于标记-整理算法实现。`这个收集器是直到`JDK 6时才开始提供的`，在此之前，新生代的Parallel Scavenge收集器一直处于相当尴尬的状态，原因是如果新生代选择了Parallel Scavenge收集器，老年代除了Serial Old(PS MarkSweep)收集器以外别无选择，其他表现良好的老年代收集器，如CMS无法与它配合工作。

由于老年代Serial Old收集器在服务端应用性能上的“拖累”，使用Parallel Scavenge收集器也未必能在整体上获得吞吐量最大化的效果。同样，由于单线程的老年代收集中无法充分利用服务器多处理器的并行处理能力，在老年代内存空间很大而且硬件规格比较高级的运行环境中，这种组合的总吞吐量甚至不一 定比ParNew加CMS的组合来得优秀。

直到Parallel Old收集器出现后，“吞吐量优先”收集器终于有了比较名副其实的搭配组合，`在注重吞吐量或者处理器资源较为稀缺的场合，都可以优先考虑Parallel Scavenge加Parallel Old收集器这个组合`。Parallel Old收集器的工作过程如图3-10所示。
![image-20201205223729029](https://gitee.com/zisuu/picture/raw/master/img/20201205223729.png)

## CMS收集器

`CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的收集器。`目前很大一部分的Java应用集中在互联网网站或者基于浏览器的B/S系统的服务端上，这类应用通常都会较为 关注服务的响应速度，希望系统停顿时间尽可能短，以给用户带来良好的交互体验。CMS收集器就非常符合这类应用的需求。

从名字(包含“Mark Sweep”)上就可以看出`CMS收集器是基于标记-清除算法实现的`，它的运作过程相对于前面几种收集器来说要更复杂一些，整个过程分为四个步骤，包括:

1. 初始标记(CMS initial mark)
2. 并发标记(CMS concurrent mark)
3. 重新标记(CMS remark)
4. 并发清除(CMS concurrent sweep)

其中`初始标记、重新标记这两个步骤仍然需要“Stop The World”`。

- 初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快;
- 并发标记阶段就是从GC Roots的直接关联对象开始遍历整个对象图的过程，这个过程耗时较长但是不需要停顿用户线程，可以与垃圾收集线程一起并发运行;
- 而重新标记阶段则是为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的 标记记录(详见并发可达性分析种关于`增量更新`的讲解)，这个阶段的停顿时间通常会比初始标记阶段稍长一 些，但也远比并发标记阶段的时间短;
- 最后是并发清除阶段，清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动存活对象，所以这个阶段也是可以与用户线程同时并发的。

由于在整个过程中耗时最长的并发标记和并发清除阶段中，垃圾收集器线程都可以与用户线程一 起工作，所以从总体上来说，CMS收集器的内存回收过程是与用户线程一起并发执行的。通过图3-11 可以比较清楚地看到CMS收集器的运作步骤中并发和需要停顿的阶段。

![image-20201205223904124](https://gitee.com/zisuu/picture/raw/master/img/20201205223904.png)

CM S是一款优秀的收集器，它最主要的优点在名字上已经体现出来:并发收集、低停顿，一些官方公开文档里面也称之为“并发低停顿收集器”(Concurrent Low Pause Collector)。CMS收集器是 HotSpot虚拟机追求低停顿的第一次成功尝试，但是它还远达不到完美的程度，至少有以下三个明显的缺点:

- 首先，CMS收集器对处理器资源非常敏感。事实上，面向并发设计的程序都对处理器资源比较敏感。在并发阶段，它虽然不会导致用户线程停顿，但却会因为占用了一部分线程(或者说处理器的计算能力)而导致应用程序变慢，降低总吞吐量。`CMS默认启动的回收线程数是(处理器核心数量 +3)/4`，也就是说，如果处理器核心数在四个或以上，并发回收时垃圾收集线程只占用不超过25%的 处理器运算资源，并且会随着处理器核心数量的增加而下降。但是当处理器核心数量不足四个时， CM S对用户程序的影响就可能变得很大。如果应用本来的处理器负载就很高，还要分出一半的运算能 力去执行收集器线程，就可能导致用户程序的执行速度忽然大幅降低。为了缓解这种情况，虚拟机提 供了一种称为`“增量式并发收集器”(Incremental Concurrent Mark Sweep/i-CMS)的CMS收集器变种`， 所做的事情和以前单核处理器年代PC机操作系统靠抢占式多任务来模拟多核并行多任务的思想一样， 是在并发标记、清理的时候让收集器线程、用户线程交替运行，尽量减少垃圾收集线程的独占资源的 时间，这样整个垃圾收集的过程会更长，但对用户程序的影响就会显得较少一些，直观感受是速度变 慢的时间更多了，但速度下降幅度就没有那么明显。实践证明增量式的CMS收集器效果很一般，从 JDK 7开始，i-CMS模式已经被声明为“deprecated”，即已过时不再提倡用户使用，到JDK 9发布后i- CM S模式被完全废弃。
- 然后，`由于CMS收集器无法处理“浮动垃圾”(FloatingGarbage)，有可能出现“Con-current Mode Failure”失败进而导致另一次完全“Stop The World”的Full GC的产生`。在CMS的并发标记和并发清理阶段，**用户线程是还在继续运行的，程序在运行自然就还会伴随有新的垃圾对象不断产生，但这一部分垃圾对象是出现在标记过程结束以后，CM S无法在当次收集中处理掉它们，只好留待下一次垃圾收集 时再清理掉。这一部分垃圾就称为“浮动垃圾”**。同样也是由于在垃圾收集阶段用户线程还需要持续运 行，那就还需要预留足够内存空间提供给用户线程使用，因此`CMS收集器不能像其他收集器那样等待 到老年代几乎完全被填满了再进行收集，必须预留一部分空间供并发收集时的程序运作使用`。`在JDK 5的默认设置下，CMS收集器当老年代使用了68%的空间后就会被激活`，这是一个偏保守的设置，如果 在实际应用中老年代增长并不是太快，可以适当调高参数`-XX:CMSInitiatingOccu-pancyFraction`的值 来提高CMS的触发百分比，降低内存回收频率，获取更好的性能。到了`JDK 6时，CMS收集器的启动 阈值就已经默认提升至92%`。但这又会更容易面临另一种风险:**要是CM S运行期间预留的内存无法满 足程序分配新对象的需要，就会`出现一次“并发失败”(Concurrent Mode Failure)，这时候虚拟机将不得不启动后备预案:冻结用户线程的执行，临时启用Serial Old收集器来重新进行老年代的垃圾收集`**， 但这样停顿时间就很长了。所以参数-XX:CMSInitiatingOccupancyFraction设置得太高将会很容易导致 大量的并发失败产生，性能反而降低，用户应在生产环境中根据实际应用情况来权衡设置。
- 还有最后一个缺点，在本节的开头曾提到，CM S是一款基于“标记-清除”算法实现的收集器，如果读者对前面这部分介绍还有印象的话，就可能想到这意味着`收集结束时会有大量空间碎片产生`。空间碎片过多时，将会给大对象分配带来很大麻烦，往往`会出现老年代还有很多剩余空间，但就是无法找到足够大的连续空间来分配当前对象，而不得不提前触发一次Full GC的情况`。为了解决这个问题， CMS收集器提供了一个`-XX:+UseCMS-CompactAtFullCollection开关参数(默认是开启的，此参数从 JDK 9开始废弃)，用于在CMS收集器不得不进行Full GC时开启内存碎片的合并整理过程`，由于这个 内 存 整 理 必 须 移 动 存 活 对 象 ， ( 在 Sh e n a n d o a h 和 Z G C 出 现 前 ) 是 无 法 并 发 的 。 这 样 空 间 碎 片 问 题 是 解 决了，但停顿时间又会变长，因此虚拟机设计者们还提供了另外一个参数`-XX:CM SFullGCsBefore- Compaction(此参数从JDK 9开始废弃)，这个参数的作用是要求CMS收集器在执行过若干次(数量 由参数值决定)不整理空间的Full GC之后，下一次进入Full GC前会先进行碎片整理(默认值为0，表 示每次进入Full GC时都进行碎片整理)`。

## Garbage First收集器

`Garbage First(简称G1)收集器是垃圾收集器技术发展历史上的里程碑式的成果，它开创了收集器面向局部收集的设计思路和基于Region的内存布局形式`。

`G1是一款主要面向服务端应用的垃圾收集器`。HotSpot开发团队最初赋予它的期望是(在比较长 期的)未来可以替换掉JDK 5中发布的CMS收集器。现在这个期望目标已经实现过半了，`JDK 9发布之 日，G1宣告取代Parallel Scavenge加Parallel Old组合，成为服务端模式下的默认垃圾收集器`，而CM S则沦落至被声明为不推荐使用(Deprecate)的收集器。如果对JDK 9及以上版本的HotSpot虚拟机使用 参数-XX:+UseConcMarkSweep GC来开启CMS收集器的话，用户会收到一个警告信息，提示CMS未 来将会被废弃

但作为一款曾被广泛运用过的收集器，经过多个版本的开发迭代后，CMS(以及之前几款收集 器)的代码与HotSpot的内存管理、执行、编译、监控等子系统都有千丝万缕的联系，这是历史原因导 致的，并不符合职责分离的设计原则。为此，规划JDK 10功能目标时，HotSpot虚拟机提出了“统一垃圾收集器接口”，将内存回收的“行为”与“实现”进行分离，CMS以及其他收集器都重构成基于这套 接口的一种实现。以此为基础，日后要移除或者加入某一款收集器，都会变得容易许多，风险也可以 控制，这算是在为CMS退出历史舞台铺下最后的道路了。

作为CM S收集器的替代者和继承人，设计者们希望做出一款能够建立起`“停顿时间模型”(Pause Prediction Model)的收集器`，`停顿时间模型的意思是能够支持指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间大概率不超过N毫秒这样的目标`，这几乎已经是实时Java(RTSJ)的中软实时垃圾收集器特征了。

首先要有一个思想上的改变，在G1收集器出现之前的所有 其他收集器，包括CMS在内，垃圾收集的目标范围要么是整个新生代(Minor GC)，要么就是整个老年代(Major GC)，再要么就是整个Java堆(Full GC)。而G1跳出了这个樊笼，`它可以面向堆内存任何部分来组成回收集(Collection Set，一般简称CSet)进行回收，衡量标准不再是它属于哪个分代，而 是哪块内存中存放的垃圾数量最多，回收收益最大，这就是G1收集器的Mixed GC模式。`

`G1开创的基于Region的堆内存布局是它能够实现这个目标的关键`。虽然G1也仍是遵循分代收集理论设计的，但其堆内存的布局与其他收集器有非常明显的差异:

`G1不再坚持固定大小以及固定数量的分代区域划分，而是把连续的Java堆划分为多个大小相等的独立区域(Region)，每一个Region都可以根据需要，扮演新生代的Eden空间、Survivor空间，或者老年代空间`。收集器能够对扮演不同角色的 Region采用不同的策略去处理，这样无论是新创建的对象还是已经存活了一段时间、熬过多次收集的旧对象都能获取很好的收集效果。

`Region中还有一类特殊的Humongous区域，专门用来存储大对象。G1认为只要大小超过了一个 R e gi o n 容 量 一 半 的 对 象 即 可 判 定 为 大 对 象 。` 每 个 R e gi o n 的 大 小 可 以 通 过 参 数`- X X : G 1 H e a p R e gi o n Si z e 设 定，取值范围为1M B~32M B，且应为2的N次幂`。而对于那些超过了整个Region容量的超级大对象， 将会被存放在N个连续的Humongous Region之中，`G1的大多数行为都把Humongous Region作为老年代 的一部分来进行看待`，如图3-12所示。

![image-20201206210652653](https://gitee.com/zisuu/picture/raw/master/img/20201206210652.png)

`虽然G1仍然保留新生代和老年代的概念，但新生代和老年代不再是固定的了，它们都是一系列区域(不需要连续)的动态集合`。G1收集器之所以能建立可预测的停顿时间模型，是因为`它将Region作为单次回收的最小单元，即每次收集到的内存空间都是Region大小的整数倍`，这样可以有计划地避免在整个Java堆中进行全区域的垃圾收集。

更具体的处理思路是让G1收集器去跟踪各个Region里面的垃圾堆积的“价值”大小，价值即回收所获得的空间大小以及回收所需时间的经验值，然后在后台维护一 个优先级列表，`每次根据用户设定允许的收集停顿时间(使用参数-XX:MaxGCPauseMillis指定，默认值是200毫秒)，优先处理回收价值收益最大的那些Region`，这也就是“Garbage First”名字的由来。 **这种使用Region划分内存空间，以及具有优先级的区域回收方式，保证了G1收集器在有限的时间内获 取尽可能高的收集效率。**

G1将堆内存“化整为零”的“解题思路”，看起来似乎没有太多令人惊讶之处，也完全不难理解，但 其中的实现细节可是远远没有想象中那么简单，否则就不会从2004年Sun实验室发表第一篇关于G1的 论文后一直拖到2012年4月JDK 7 Update 4发布，用将近10年时间才倒腾出能够商用的G1收集器来。 G1收集器至少有(不限于)以下这些关键的细节问题需要妥善解决:

- 譬如，`将Java堆分成多个独立Region后，Region里面存在的跨Region引用对象如何解决?`使用记忆集避免全堆作为GC Roots扫描，但在G1收集器上记忆集的应用其实要复杂很多，`它的每个Region都维护有自己的记忆集，这些记忆集会记录下别的Region 指向自己的指针，并标记这些指针分别在哪些卡页的范围之内`。`G1的记忆集在存储结构的本质上是一 种 哈 希 表 ， K e y 是 别 的 R e g i o n 的 起 始 地 址 ， Va l u e 是 一 个 集 合 ， 里 面 存 储 的 元 素 是 卡 表 的 索 引 号` 。 这 种“双向”的卡表结构(卡表是“我指向谁”，这种结构还记录了“谁指向我”)比原来的卡表实现起来更 复杂，同时由于Region数量比传统收集器的分代数量明显要多得多，因此G1收集器要比其他的传统垃 圾收集器有着更高的内存占用负担。根据经验，`G1至少要耗费大约相当于Java堆容量10%至20%的额 外内存来维持收集器工作。`
- 譬如，`在并发标记阶段如何保证收集线程与用户线程互不干扰地运行?`这里首先要解决的是用户线程改变对象引用关系时，必须保证其不能打破原本的对象图结构，导致标记结果出现错误，该问题 的解决办法笔者已经抽出独立小节来讲解过(见3.4.6节):`CMS收集器采用增量更新算法实现，而G1 收集器则是通过原始快照(SATB)算法来实现的`。此外，垃圾收集对用户线程的影响还体现在回收过 程中新创建对象的内存分配上，程序要继续运行就肯定会持续有新对象被创建，`G1为每一个Region设 计了两个名为TAMS(Top at Mark Start)的指针，把Region中的一部分空间划分出来用于并发回收过 程中的新对象分配，并发回收时新分配的对象地址都必须要在这两个指针位置以上。`G1收集器默认在 这个地址以上的对象是被隐式标记过的，即默认它们是存活的，不纳入回收范围。`与CMS中 的“Concurrent M ode Failure”失败会导致Full GC类似，如果内存回收的速度赶不上内存分配的速度， G1收集器也要被迫冻结用户线程执行，导致Full GC而产生长时间“Stop The World”。`
- 譬如，`怎样建立起可靠的停顿预测模型?`用户通过-XX:M axGCPauseM illis参数指定的停顿时间 只意味着垃圾收集发生之前的期望值，但G1收集器要怎么做才能满足用户的期望呢?G1收集器的停顿 预测模型是以衰减均值(Decaying Average)为理论基础来实现的，`在垃圾收集过程中，G1收集器会记 录每个Region的回收耗时、每个Region记忆集里的脏卡数量等各个可测量的步骤花费的成本，并分析得 出平均值、标准偏差、置信度等统计信息`。这里强调的“衰减平均值”是指它会比普通的平均值更容易 受到新数据的影响，平均值代表整体平均状态，但衰减平均值更准确地代表“最近的”平均状态。换句 话说，Region的统计状态越新越能决定其回收的价值。然后通过这些信息预测现在开始回收的话，由 哪些Region组成回收集才可以在不超过期望停顿时间的约束下获得最高的收益。

**如果我们不去计算用户线程运行过程中的动作(如使用写屏障维护记忆集的操作)，G1收集器的 运作过程大致可划分为以下四个步骤:**

- `初始标记(Initial Marking):`仅仅只是标记一下GC Roots能直接关联到的对象，并且修改TAMS 指针的值，让下一阶段用户线程并发运行时，能正确地在可用的Region中分配新对象。`这个阶段需要停顿线程，但耗时很短，而且是借用进行Minor GC的时候同步完成的，所以G1收集器在这个阶段实际 并没有额外的停顿。`
- `并发标记(Concurrent Marking)`:从GC Root开始对堆中对象进行可达性分析，递归扫描整个堆里的对象图，找出要回收的对象，这阶段耗时较长，但可与用户程序并发执行。当对象图扫描完成以 后，还要重新处理SATB记录下的在并发时有引用变动的对象。
- `最终标记(Final Marking):`对用户线程做另一个短暂的暂停，用于处理并发阶段结束后仍遗留 下来的最后那少量的SATB记录。
- `筛选回收(Live Data Counting and Evacuation):`负责更新Region的统计数据，对各个Region的回收价值和成本进行排序，根据用户所期望的停顿时间来制定回收计划，可以自由选择任意多个Region 构成回收集，然后把决定回收的那一部分Region的存活对象复制到空的Region中，再清理掉整个旧 Region的全部空间。`这里的操作涉及存活对象的移动，是必须暂停用户线程，由多条收集器线程并行完成的。`

从上述阶段的描述可以看出，`G1收集器除了并发标记外，其余阶段也是要完全暂停用户线程的`， 换言之，它并非纯粹地追求低延迟，官方给它**设定的目标是在延迟可控的情况下获得尽可能高的吞吐量，所以才能担当起“全功能收集器”的重任与期望。**

从Oracle官方透露出来的信息可获知，回收阶段(Evacuat ion)其实本也有想过设计成与用户程序 一起并发执行，但这件事情做起来比较复杂，考虑到G1只是回收一部分Region，停顿时间是用户可控 制的，所以并不迫切去实现，而选择把这个特性放到了G1之后出现的低延迟垃圾收集器(即ZGC) 中。另外，还考虑到G1不是仅仅面向低延迟，停顿用户线程能够最大幅度提高垃圾收集效率，为了保 证吞吐量所以才选择了完全暂停用户线程的实现方案。通过图3-13可以比较清楚地看到G1收集器的运 作步骤中并发和需要停顿的阶段。
![image-20201206211514227](https://gitee.com/zisuu/picture/raw/master/img/20201206211514.png)

毫无疑问，可以由用户指定期望的停顿时间是G1收集器很强大的一个功能，设置不同的期望停顿 时间，可使得G1在不同应用场景中取得关注吞吐量和关注延迟之间的最佳平衡。不过，这里设置 的“期望值”必须是符合实际的，不能异想天开，毕竟G1是要冻结用户线程来复制对象的，这个停顿时 间再怎么低也得有个限度。它·默认的停顿目标为两百毫秒·，一般来说，回收阶段占到几十到一百甚至 接近两百毫秒都很正常，但如果我们把停顿时间调得非常低，譬如设置为二十毫秒，很可能出现的结 果就是由于停顿目标时间太短，导致每次选出来的回收集只占堆内存很小的一部分，收集器收集的速 度逐渐跟不上分配器分配的速度，导致垃圾慢慢堆积。很可能一开始收集器还能从空闲的堆内存中获 得一些喘息的时间，但应用运行时间一长就不行了，最终占满堆引发Full GC反而降低性能，`所以通常 把期望停顿时间设置为一两百毫秒或者两三百毫秒会是比较合理的。`

## G1对比CMS

相比CMS，G1的优点有很多，暂且不论`可以指定最大停顿时间、分Region的内存布局、按收益动态确定回收集`这些创新性设计带来的红利，单从最传统的算法理论上看，G1也更有发展潜力。与CMS 的“标记-清除”算法不同，`G1从整体来看是基于“标记-整理”算法实现的收集器`，`但从局部(两个Region 之间)上看又是基于“标记-复制”算法实现`，无论如何，这两种算法都意味着`G1运作期间不会产生内存 空间碎片，垃圾收集完成之后能提供规整的可用内存`。这种特性有利于程序长时间运行，在程序为大 对象分配内存时不容易因无法找到连续内存空间而提前触发下一次收集。

不过，G1相对于CMS仍然不是占全方位、压倒性优势的，从它出现几年仍不能在所有应用场景中代替CMS就可以得知这个结论。比起CMS，G1的弱项也可以列举出不少，如在用户程序运行过程 中，`G1无论是为了垃圾收集产生的内存占用(Footprint)还是程序运行时的额外执行负载 (Overload)都要比CMS要高。`

- 就内存占用来说，虽然G1和CMS都使用卡表来处理跨代指针，但G1的卡表实现更为复杂，而且 堆中每个Region，无论扮演的是新生代还是老年代角色，都必须有一份卡表，这导致G1的记忆集(和 其他内存消耗)可能会占整个堆容量的20%乃至更多的内存空间;相比起来CMS的卡表就相当简单， 只有唯一一份，而且只需要处理老年代到新生代的引用，反过来则不需要，由于新生代的对象具有朝生夕灭的不稳定性，引用变化频繁，能省下这个区域的维护开销是很划算的。
- 在执行负载的角度上，同样由于两个收集器各自的细节实现特点导致了用户程序运行时的负载会 有不同，譬如它们都使用到写屏障，CMS用写后屏障来更新维护卡表;而G1除了使用写后屏障来进行 同样的(由于G1的卡表结构复杂，其实是更烦琐的)卡表维护操作外，`为了实现原始快照搜索 (SATB)算法，还需要使用写前屏障来跟踪并发时的指针变化情况`。相比起增量更新算法，原始快照 搜索能够减少并发标记和重新标记阶段的消耗，避免CMS那样在最终标记阶段停顿时间过长的缺点， 但是在用户程序运行过程中确实会产生由跟踪引用变化带来的额外负担。由于G1对写屏障的复杂操作 要比CM S消耗更多的运算资源，所以CM S的写屏障实现是直接的同步操作，而G1就不得不将其实现 为类似于消息队列的结构，把写前屏障和写后屏障中要做的事情都放到队列里，然后再异步处理。

以上的优缺点对比仅仅是针对G1和CM S两款垃圾收集器单独某方面的实现细节的定性分析，通常 我们说哪款收集器要更好、要好上多少，往往是针对具体场景才能做的定量比较。

`目前在小内存应用上CMS的表现大概率仍然要会优于G1`，而`在大内存应用上G1则大多能发挥其 优势，这个优劣势的Java堆容量平衡点通常在6GB至8GB之间`，当然，以上这些也仅是经验之谈，不 同应用需要量体裁衣地实际测试才能得出最合适的结论，随着HotSpot的开发者对G1的不断优化，也 会让对比结果继续向G1倾斜。