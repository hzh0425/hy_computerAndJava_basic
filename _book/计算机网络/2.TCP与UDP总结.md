## 3.tcp和udp的对比

![TCP、UDP协议的区别](https://my-blog-to-use.oss-cn-beijing.aliyuncs.com/2019-11/tcp-vs-udp.jpg)

### 相同点

UDP协议和TCP协议都是传输层协议。

TCP（Transmission Control Protocol，传输控制协议）提供的是面向连接，可靠的字节流服务。即客户和服务器交换数据前，必须现在双方之间建立一个TCP连接，之后才能传输数据。并且提供超时重发，丢弃重复数据，检验数据，流量控制等功能，保证数据能从一端传到另一端。

UDP（User Data Protocol，用户数据报协议）是一个简单的面向数据报的运输层协议。它不提供可靠性，只是把应用程序传给IP层的数据报发送出去，但是不能保证它们能到达目的地。由于UDP在传输数据报前不用再客户和服务器之间建立一个连接，且没有超时重发等机制，所以传输速度很快。

### 不同点

- 报头不同
- 特点不同
- 协议不同

### 3.1 udp的特点

- 报头
  ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20180901091529706.png)

**UDP数据报最大长度64K（包含UDP首部），如果数据长度超过64K就需要在应用层手动分包，UDP无法保证包序，需要在应用层进行编号。**

- 特点

  1. **无连接：**知道对端的IP和端口号就直接进行传输, 不需要建立连接。
  2. **不可靠：**没有确认机制, 没有重传机制; 如果因为网络故障该段无法发到对方, UDP协议层也不会给应用层返回任何错误信息。
  3. **面向数据报：**不能够灵活的控制读写数据的次数和数量，应用层交给UDP多长的报文, UDP原样发送, 既不会拆分, 也不会合并。
  4. 数据收不够灵活，但是能够明确区分两个数据包，**避免粘包**问题。

- 协议：

  NFS: 网络文件系统
  TFTP: 简单文件传输协议
  DHCP: 动态主机配置协议
  BOOTP: 启动协议(用于无盘设备启动)
  DNS: 域名解析协议

### 3.2 tcp的特点

#### 3.2.0 报头

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20180901092556271.png)

```
源/目的端口号: 表示数据是从哪个进程来, 到哪个进程去;
32位序号/32位确认号: 不一定从0开始（作用：保证确认应答；保证数据按序到达；去重）
4位TCP报头长度: 表示该TCP头部有多少个32位bit(有多少个4字节); 所以TCP报头最大长度是15 * 4 = 60 字节
6位标志位:
    1. URG: 紧急指针是否有效
    2. ACK: 确认号是否有效
    3. PSH: 提示接收端应用程序立刻从TCP缓冲区把数据读走
    4. RST: 对方要求重新建立连接; 我们把携带RST标识的称为复位报文段
    5. SYN: 请求建立连接; 我们把携带SYN标识的称为同步报文段
    6. FIN: 通知对方, 本端要关闭了, 我们称携带FIN标识的为结束报文段
16位窗口大小: 接收缓冲区剩余的空间大小 
16位校验和: 发送端填充, CRC校验. 接收端校验不通过, 则认为数据有问题. 此处的检验和不光包含TCP 首部, 也包含TCP数据部分. 
16位紧急指针: 标识哪部分数据是紧急数据; 12345678910111213
```

- 特点
  - **面向连接**

#### 3.2.1 tcp面向连接

##### 3.2.1.1 三次握手

#### ****

**在通信之前，会先通过三次握手的机制来确认两端口之间的连接是否可用。而UDP是不需要确认的，直接传**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170605110405666.png)![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190215155632492.png)

> **最开始的时候客户端和服务器都是处于CLOSED状态。主动打开连接的为客户端，被动打开连接的是服务器。**
>
> **某个时刻客户端和服务器要进行通信，此时双方都有备好的端口，服务器的端口会处于监听状态，等待客户端的连接。**

**怎么知道服务器端口号的？**

​    http在访问url中已经拿到！

**怎么知道客户端要连接进来，服务器才进入listen状态？**

​    TCP老早就创建了传输控制块TCB，时刻待命准备接受客户端的连接请求，此时服务器就被动地进入了listen状态。

 

**第一次握手：**

客户端想要连接，创建传输控制块TCB，状态变为主动打开。发送给服务器不包含数据内容的连接请求报文。该请求报文首部中同步位SYN=1，同时选择一个初始序列号seq=x（携带了x个字节）。然后客户端进入 SYN-SENT （同步已发送）状态，告诉服务器我想和你同步连接。TCP规定，SYN报文段（SYN=1的报文段）不能携带数据，但需要消耗掉一个序号。

**第二次握手：**

TCP服务器收到连接请求报文，如果同意连接则发送确认报文。为了保证下次客户端发送报文时seq序列号是正确的，需要发送确认号ack=x+1，同时确认号ack要生效必须发送ACK=1，再加上同步位SYN=1，序列号seq=y（携带Y个字节），然后服务器也进 入SYN-RCVD (同步已收到) 状态，完成同步连接。这个报文也是SYN报文，也不能携带数据，但是同样要消耗一个序号。 

**第三次握手：**

 客户端收到确认后还要再向服务器发送确认报文。确认报文已经不是请求报文SYN了，不再包含SYN同步位。发送的内容有序列号seq=x+1（和第二次握手的ACK对应），确认号ack=y+1，ACK=1。客户端发送确认报文以后进入ESTABLISHED（已建立）状态，服务器接收到确认报文以后也进入ESTABLISHED状态。此时TCP连接完成建立。

**然后就可以发送TCP接收到Http的数据包后生成的新数据包了！**

 

> **但是貌似看起来两次握手请求就可以完成事，为什么非要三次握手呢？**
>
> 主要是为了防止已经失效的连接请求报文突然又传到了服务器，从而产生错误。
>
> 如果是两次握手，假设一种情景：客户端发送了第一个请求连接报文并未丢失，只是因为网络问题在网络节点中滞留太久了。由于客户端迟迟没有收到确认报文，以为服务器没有收到。于是再发送一条请求连接报文，此时一路畅通完成两次握手建立连接，传输数据，关闭连接。然后那个前一条龟速的请求报文终于走到了服务器，再次和服务器建立连接，这就造成了不必要的资源浪费。
>
> 如果是三次握手，就算那一条龟速的请求报文最后到达了服务器，然后服务器也发送了确认连接报文，但是此时客户端已经不会再发出确认报文了，服务器也接受不到确认报文，于是无法建立连接。

> 

##### 3.2.1.2,四次挥手

**数据传输完毕后，双方都可释放连接。最开始的时候，客户端和服务器都是处于ESTABLISHED状态，然后客户端主动关闭，服务器被动关闭。**

![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20170606084851272.png)

**第一次挥手：**

客户端从ESTABLISHED状态变为主动关闭状态，客户端发送请求释放连接报文给服务器，FIN=1，seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。

**第二次挥手：**

服务器接收到客户端发来的请求释放报文以后，发送确认报文告诉客户端我收到了你的请求，内容差不多就是seq=v，ack=u+1，ACK=1，此时服务器进入CLOSE-WAIT（关闭等待）状态。

为什么是CLOSE-WAIT状态？可能自己服务器这端还有数据没有发送完，所以这个时候整个TCP的连接就变成了半关闭状态。服务器还能发送数据，客户端也能接收数据，但客户端不能再发送数据了，只能发送确认报文。

客户端接收到服务器传来的确认报文以后，进入 FIN-WAIT-1（终止等待2）状态，等待服务器发送连接释放的报文（在这之前，还需要接受服务器没有发送完的最后的数据）。 

**第三次挥手：**

服务器所有的数据都发送完了，认为可以关闭连接了，于是向客户端发送连接释放报文，内容FIN=1，seq=w，ack=u+1（客户端没发送消息，所以提醒客户端下一次还是从u+1开始发送序列），ACK=1。此时服务器进入了 LAST-ACK（最后确认）状态，等待客户端发送确认报文。

**第四次挥手：**

客户端接收到了服务器发送的连接释放报文，必须发出确认。确认报文seq=u+1，ack=w+1，ACK=1。此时客户端进入 TIME-WAIT （时间等待）状态，但是没有立马关闭。此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。

因为这个确认报文可能丢失。服务器收不到确认报文心想这可能是我没传到或者丢失了啊，于是服务器再传一个FIN，然后客户端再重新发送一个确认报文。然后刷新2∗∗MSL时间。直到这个时间内收不到FIN连接释放报文，客户端撤销TCB进入CLOSE状态。

而服务器，在接收到确认报文的时候就立马变为CLOSE状态了。所以服务器结束TCP连接的时间略早于客户端。

 

> **万一确认连接以后客户端故障怎么办？**
>
> TCP设有一个保活计时器。显然客户端故障时服务器不会智障般等下去，白白浪费资源。服务器每次收到一次客户端的请求以后都会刷新这个保活计时器，时间通常设置为2小时。若2个小时依旧没有收到客户端的任何数据，服务器会发送一个探测报文段，每隔75分钟发一个，如果连发十个都没有数据反应，那么服务器就知道客户端故障了，关闭连接。

#### 3.2.2 tcp可靠传输

1. 应用数据被分割成 TCP 认为最适合发送的数据块。 
2. TCP 给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 
3. **校验和：** TCP 将保持它首部和数据的检验和。这是一个端到端的检验和，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP 将丢弃这个报文段和不确认收到此报文段。 
4. TCP 的接收端会丢弃重复的数据。 
5. **流量控制：** TCP 连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP 使用的流量控制协议是可变大小的滑动窗口协议。 （TCP 利用滑动窗口实现流量控制）
6. **拥塞控制：** 当网络拥塞时，减少数据的发送。
7. **ARQ协议：** 也是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组。
8. **超时重传：** 当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 

##### 4.1 ARQ协议

**自动重传请求**（Automatic Repeat-reQuest，ARQ）是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。

###### 停止等待ARQ协议

- 停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到 ACK 确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组；
- 在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；

**优点：** 简单

**缺点：** 信道利用率低，等待时间长

**1) 无差错情况:**

发送方发送分组,接收方在规定时间内收到,并且回复确认.发送方再次发送。

**2) 出现差错情况（超时重传）:**

停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为 **自动重传请求 ARQ** 。另外在停止等待协议中若收到重复分组，就丢弃该分组，但同时还要发送确认。**连续 ARQ 协议** 可提高信道利用率。发送维持一个发送窗口，凡位于发送窗口内的分组可连续发送出去，而不需要等待对方确认。接收方一般采用累积确认，对按序到达的最后一个分组发送确认，表明到这个分组位置的所有分组都已经正确收到了。

**3) 确认丢失和确认迟到**

- **确认丢失** ：确认消息在传输过程丢失。当A发送M1消息，B收到后，B向A发送了一个M1确认消息，但却在传输过程中丢失。而A并不知道，在超时计时过后，A重传M1消息，B再次收到该消息后采取以下两点措施：1. 丢弃这个重复的M1消息，不向上层交付。 2. 向A发送确认消息。（不会认为已经发送过了，就不再发送。A能重传，就证明B的确认消息丢失）。
- **确认迟到** ：确认消息在传输过程中迟到。A发送M1消息，B收到并发送确认。在超时时间内没有收到确认消息，A重传M1消息，B仍然收到并继续发送确认消息（B收到了2份M1）。此时A收到了B第二次发送的确认消息。接着发送其他数据。过了一会，A收到了B第一次发送的对M1的确认消息（A也收到了2份确认消息）。处理如下：1. A收到重复的确认后，直接丢弃。2. B收到重复的M1后，也直接丢弃重复的M1。

###### 连续ARQ协议

连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。

**优点：** 信道利用率高，容易实现，即使确认丢失，也不必重传。

**缺点：** 不能向发送方反映出接收方已经正确收到的所有分组的信息。 比如：发送方发送了 5条 消息，中间第三条丢失（3号），这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 Go-Back-N（回退 N），表示需要退回来重传已经发送过的 N 个消息。

##### 4.2 滑动窗口和流量控制

> ## 概述
>
> 滑动窗口实现了TCP流控制。首先明确**滑动窗口**的范畴：TCP是双工的协议，会话的双方都可以同时接收和发送数据。TCP会话的双方都各自维护一个`发送窗口`和一个`接收窗口`。各自的`接收窗口`大小取决于应用、系统、硬件的限制（TCP传输速率不能大于应用的数据处理速率）。各自的`发送窗口`则要求取决于对端通告的`接收窗口`，要求相同。
>
> 滑动窗口解决的是**流量控制**的的问题，就是如果接收端和发送端对数据包的处理速度不同，如何让双方达成一致。接收端的缓存传输数据给应用层，但这个过程不一定是即时的，如果发送速度太快，会出现接收端数据overflow，流量控制解决的是这个问题。
>
> ## 窗口的概念
>
> 发送方的发送缓存内的数据都可以被分为4类:
> \1. 已发送，已收到ACK
> \2. 已发送，未收到ACK
> \3. 未发送，但允许发送
> \4. 未发送，但不允许发送
>
> 其中类型2和3都属于发送窗口。
>
> 接收方的缓存数据分为3类：
> \1. 已接收
> \2. 未接收但准备接收
> \3. 未接收而且不准备接收
>
> 其中类型2属于接收窗口。
>
> 窗口大小代表了设备一次能从对端处理多少数据，之后再传给应用层。缓存传给应用层的数据不能是乱序的，窗口机制保证了这一点。现实中，应用层可能无法立刻从缓存中读取数据。
>
> ## 滑动机制
>
> 1. 发送窗口只有收到发送窗口内字节的ACK确认，才会移动发送窗口的左边界。
> 2. 接收窗口只有在前面所有的段都确认的情况下才会移动左边界。当在前面还有字节未接收但收到后面字节的情况下，窗口不会移动，并不对后续字节确认。以此确保对端会对这些数据重传。
> 3. 遵循快速重传、累计确认、选择确认等规则。
> 4. 发送方发的window size = 8192;就是接收端最多发送8192字节，这个8192一般就是发送方接收缓存的大小。
>
> ## 模拟动画
>
> ### 模拟特点
>
> 找到了一个模拟TCP窗口发送的[动画的地址](http://www.exa.unicen.edu.ar/catedras/comdat1/material/Filminas3_Practico3.swf)，稍微有缺陷：1. 丢包率如果设得太高，有时无论重发多少次都不能恢复正常 2. 窗口最大可为10，其实应该为9
>
> 明确发送端和接收端，发送A~S数据包，我们不会从头到尾分析，因为过程比较长。
> \1. 简化了窗口大小，双方窗口大小都一直是4
> \2. 设置一定的丢包率，否则没什么值得分析的，包括sender发送的数据包和receiver回复的ACK包。
> \3. 简化重传机制，出现丢包则直接重传，不等3个冗余ACK和超时。
> \4. 既不是选择重传也不是退回N步，重传的包是随机的
> 发
>
> ### 分析滑动窗口机制
>
> 1. 首先发送端发送A,B,C,D四个包，但是A,B丢失，只有C,D到达接收端。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\42138740462_ed4ce64c1b_b-1600147916917.jpg)
> 2. 接收端没有收到A，所以不回复ACK包。发送端重传A,B,C,D四个包，这次全都到达了。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\42138740402_dbbbf52c8c_b-1600147916277.jpg)
> 3. 接收端先获得A，发ACK包A，但是中途丢失；获得B后，根据累计确认的原则，发D的ACK包，然后窗口滑动。再次获得C,D后，连续回复2个D的ACK包，其中C对应的ACK包丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728687_a5673da755_b-1600147916965.jpg)
> 4. 发送端连收2个D的ACK包，说明4个包对方都已收到，窗口滑动，发E,F,G,H包，其中G包丢失。现在整个序列的状态：ABCD是已发送已确认，EFGH是已发送未确认，I~S是不能发送。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728577_04e0867716_b-1600147917029.jpg)
> 5. 接收端先收到E，发ACK包；收到F后发F的ACK包；未收到G，还是发F的ACK包；收到H，还是发F的ACK包。不幸的是，三个ACK包全都丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728427_a5b7d4b107_b-1600147916757.jpg)
> 6. 发送端收到E的ACK包，窗口向右滑动一位；然后再发送F,G,H,I，其中F丢失。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728297_65698014e9_b-1600147916813.jpg)
> 7. 接收端获得I，因为没有G，只好回复F的ACK包。相继收到G,H包。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\28312507728_96c5813bee_b-1600147917133.jpg)
> 8. 接收端根据累计确认，连发两个I包，其中H对应的丢失。窗口向右滑动。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\41284211495_31f906941b_b-1600147917165.jpg)
> 9. 发送端接收I的ACK包后，向右滑动四位。发送J,K,L,M四个包，后面不再分析。
>    ![img](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\27313728077_b406cc3293_b-1600147917073.jpg)
>
> 从上面的过程中，我们可以得到以下结论：
> \1. TCP连接是通过数据包和ACK实现的，我们作为第三者可以看到双方发包的过程，但接受者在收到之前不知道发送方发的是什么，同样的，发送方在收到ACK前也不知道对方是否成功接收。
>
> 1. 发送方没有收到接收方发回的ACK，就不能向右滑动。假设发送方向接收方发了ABCD就滑动，只要对方没收到A，就不能滑动，那么就会出现二者不同步的局面。
> 2. 滑动窗口提高了信道利用率，TCP是发送报文段为单位的，假如每发一个报文就要等ACK，那么对于大数据包，等待时间就太长了。只要发送的报文在滑动窗口里面，不用等每个ACK回来就可以向右滑动。本例中，开始接收端空着AB，只有CD，此时不能滑动；之后接收到EF和H，直接向右滑动2位，不必等G到位。
> 3. 窗口大小不能大于序号空间大小的一半。目的是为了不让两个窗口出现交迭，比如总大小为7，窗口大小都为4，接收窗口应当滑动4，但只剩3个序号，导致两个窗口交迭。
> 4. 有一种情况没出现：发送方发ABCD，接收方都收到然后向右滑动，但回复的ACK包全丢了。发送方未收到任何ACK， timeout后会重发ABCD，此时的接收方按累计确认的原则，收到ABCD后只会重发D的ACK，发送方收到后向右滑动。
>
> ## 对比滑动窗口和拥塞窗口
>
> 滑动窗口是控制接收以及同步数据范围的，通知发送端目前接收的数据范围，用于流量控制，接收端使用。拥塞窗口是控制发送速率的，避免发的过多，发送端使用。因为tcp是全双工，所以两边都有滑动窗口。
> 两个窗口的维护是独立的，滑动窗口主要由接收方反馈缓存情况来维护，拥塞窗口主要由发送方的拥塞控制算法检测出的网络拥塞程度来决定的。
>
> 拥塞窗口控制sender向connection传输数据的速率，使这个速率为网络拥堵状况的函数。

##### 4.3 拥塞控制

> 在某段时间，若**对网络中某一资源的需求超过了该资源所能提供的可用部分，网络性能就要变坏**，这种情况就叫做**网络拥塞**。
>
> 在计算机网络中数位链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。
>
> 若**出现拥塞而不进行控制**，整个网络的**吞吐量将随输入负荷的增大而下降**。
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731190238241-1600147962824.png)
> 当输入的负载到达一定程度 吞吐量不会增加，即一部分网络资源会丢失掉，网络的吞吐量维持在其所能控制的最大值，转发节点的缓存不够大这造成分组的丢失是拥塞的征兆。
> **TCP的四种拥塞控制算法**
> 1.慢开始
> 2.拥塞控制
> 3.快重传
> 4.快恢复
> **假定**：
> 1.数据是单方向传送，而另一个方向只传送确认
> 2.接收方总是有足够大的缓存空间，因而发送发发送窗口的大小由网络的拥塞程度来决定
> 3.以TCP报文段的个数为讨论问题的单位，而不是以字节为单位
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731155254165-1600147963079.png)
> **示例如下：**
> 传输轮次：发送方给接收方发送数据报文段后，接收方给发送方发回相应的确认报文段，一个传输轮次所经历的时间就是往返时间RTT(RTT并非是恒定的数值），使用传输轮次是为了强调，把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个报文段的确认，拥塞窗口cwnd会随着网络拥塞程度以及所使用的拥塞控制算法动态变化。
>
> 在tcp双方建立逻辑链接关系时， 拥塞窗口cwnd的值被设置为1，还需设置慢开始门限ssthresh,在执行慢开始算法时，发送方每收到一个对新报文段的确认时，就把拥塞窗口cwnd的值加一，然后开始下一轮的传输，当拥塞窗口cwnd增长到慢开始门限值时，就使用拥塞避免算法。
>
> **慢开始：**
> 假设当前发送方拥塞窗口cwnd的值为1，而发送窗口swnd等于拥塞窗口cwnd，因此发送方当前只能发送一个数据报文段（拥塞窗口cwnd的值是几，就能发送几个数据报文段），接收方收到该数据报文段后，给发送方回复一个确认报文段，发送方收到该确认报文后，将拥塞窗口的值变为2，
>
> > 发送方此时可以连续发送两个数据报文段，接收方收到该数据报文段后，给发送方一次发回2个确认报文段，发送方收到这两个确认报文后，将拥塞窗口的值加2变为4，发送方此时可连续发送4个报文段，接收方收到4个报文段后，给发送方依次回复4个确认报文，发送方收到确认报文后，将拥塞窗口加4，置为8，发送方此时可以连续发送8个数据报文段，接收方收到该8个数据报文段后，给发送方一次发回8个确认报文段，发送方收到这8个确认报文后，将拥塞窗口的值加8变为16，
>
> 当前的拥塞窗口cwnd的值已经等于慢开始门限值，之后改用拥塞避免算法。
>
> **拥塞避免：**
> 也就是每个传输轮次，拥塞窗口cwnd只能线性加一，而不是像慢开始算法时，每个传输轮次，拥塞窗口cwnd按指数增长。同理，16+1……直至到达24，假设24个报文段在传输过程中丢失4个，接收方只收到20个报文段，给发送方依次回复20个确认报文段，一段时间后，丢失的4个报文段的重传计时器超时了，发送发判断可能出现拥塞，更改cwnd和ssthresh.并重新开始慢开始算法，如图所示：
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731165743903-1600147962820.png)![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731165605396-1600147963079.png)
> **快速重传：**
> 发送方发送1号数据报文段，接收方收到1号报文段后给发送方发回对1号报文段的确认，在1号报文段到达发送方之前，发送方还可以将发送窗口内的2号数据报文段发送出去，接收方收到2号报文段后给发送方发回对2号报文段的确认，在2号报文段到达发送方之前，发送方还可以将发送窗口内的3号数据报文段发送出去，
>
> > 假设该报文丢失，发送方便不会发送针对该报文的确认报文给发送方，发送方还可以将发送窗口内的4号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，发送方还可以将发送窗口中的5号报文段发送出去,接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段,，发送方还可以将发送窗口内的最后一个数据段即6号数据报文段发送出去，接收方收到后，发现这不是按序到达的报文段，因此给发送方发送针对2号报文段的重复确认，表明我现在希望收到的是3号报文段，但是我没有收到3号报文段，而收到了未按序到达的报文段，
>
> 此时，发送方收到了累计3个连续的针对2号报文段的重复确认，立即重传3号报文段，接收方收到后，给发送方发回针对6号报文的确认，表明，序号到6为至的报文都收到了，这样就不会造成发送方对3号报文的超时重传，而是提早收到了重传。
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184314574-1600147962875.png)
> ![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184640178-1600147963079.png)![在这里插入图片描述](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20190731184935595-1600147963079.png)

#### 3.2.3 tcp面向字节流

##### 3.2.3.1 粘包问题的原因

> 在进行Java NIO学习时，发现，如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况，这就是TCP协议中经常会遇到的粘包以及拆包的问题。
>
> 我们都知道TCP属于传输层的协议，传输层除了有TCP协议外还有UDP协议。那么UDP是否会发生粘包或拆包的现象呢？答案是不会。UDP是基于报文发送的，从UDP的帧结构可以看出，在UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP是基于字节流的，虽然应用层和TCP传输层之间的数据交互是大小不等的数据块，但是TCP把这些数据块仅仅看成一连串无结构的字节流，没有边界；另外从TCP的帧结构也可以看出，在TCP的首部没有表示数据长度的字段，基于上面两点，在使用TCP传输数据时，才有粘包或者拆包现象发生的可能。
>
> ### 粘包、拆包表现形式
>
> 现在假设客户端向服务端连续发送了两个数据包，用packet1和packet2来表示，那么服务端收到的数据可以分为三种，现列举如下：
>
> 第一种情况，接收端正常收到两个数据包，即没有发生拆包和粘包的现象，此种情况不在本文的讨论范围内。![normal](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144359680)
>
> 第二种情况，接收端只收到一个数据包，由于TCP是不会出现丢包的，所以这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理。![one](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144417818)
>
> 第三种情况，这种情况有两种表现形式，如下图。接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。这两种情况如果不加特殊处理，对于接收端同样是不好处理的。![half_one](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144437428)![one_half](D:\Typora\java核心\操作系统,计算机网络\计算机网络\assets\20160722144453881)
>
> ### 粘包、拆包发生原因
>
> 发生TCP粘包或拆包有很多原因，现列出常见的几点，可能不全面，欢迎补充，
>
> 1、要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包。
>
> 2、待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。
>
> 3、要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包。
>
> 4、接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。
>
> 等等。

##### 3.2.3.2 粘包问题解决方案

> ### 粘包、拆包解决办法
>
> 通过以上分析，我们清楚了粘包或拆包发生的原因，那么如何解决这个问题呢？解决问题的关键在于如何给每个数据包添加边界信息，常用的方法有如下几个：
>
> 1、发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了。
>
> 2、发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。
>
> 3、可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开。
>
> 等等。
>
> 

### 4.http长连接